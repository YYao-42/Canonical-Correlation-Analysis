{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "from scipy.stats import zscore, pearsonr\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data preparation\n",
    "\n",
    "**EEG signals:** Load EEGLAB datasets -> Re-reference -> Highpass filter -> downsample\n",
    "\n",
    "**Features of the video:** Extracted with Dmochowski's code (https://github.com/dmochow/SRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video features\n",
    "features_data = scipy.io.loadmat('../Correlated Component Analysis/data/features.mat')\n",
    "fsStim = int(features_data['fsVideo']) # fs of the video \n",
    "features = np.nan_to_num(features_data['muFlow']) # feature: optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EEGLAB dataset and revise dataset info\n",
    "eeglab_set = '../../Experiments/data/AS/Parra.set'\n",
    "raw_lab = mne.io.read_raw_eeglab(eeglab_set, preload=True)\n",
    "fsEEG = raw_lab.info['sfreq']\n",
    "raw_lab.rename_channels({'B1': 'Fpz', 'B2': 'Fp2', 'B3': 'AF8', 'B4': 'AF4',\n",
    "'B5': 'Afz', 'B6': 'Fz', 'B7': 'F2','B8': 'F4', 'B9': 'F6', 'B10': 'F8',\n",
    "'B11': 'FT8', 'B12': 'FC6', 'B13': 'FC4', 'B14': 'FC2', 'B15': 'FCz', 'B16': 'Cz', \n",
    "'B17': 'C2', 'B18': 'C4', 'B19': 'C6', 'B20': 'T8', 'B21': 'TP8', 'B22': 'CP6',\n",
    "'B23': 'CP4', 'B24': 'CP2', 'B25': 'P2', 'B26': 'P4', 'B27': 'P6', 'B28': 'P8', \n",
    "'B29': 'P10', 'B30': 'PO8', 'B31': 'PO4', 'B32': 'O2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualization (not re-referenced)\n",
    "# It allows visual inspection and to manually select bad channels or data spans\n",
    "# Skip for now\n",
    "# raw_lab.plot(n_channels=64, scalings='auto')\n",
    "# raw_lab.compute_psd().plot(average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-reference\n",
    "raw_lab.set_eeg_reference(ref_channels=['Cz']) # Select the reference channel to be Cz\n",
    "# TODO: Is removing dc offset necessary after re-referencing?\n",
    "# Highpass filter - remove slow drifts\n",
    "HP_cutoff = 0.5\n",
    "raw_highpass = raw_lab.copy().filter(l_freq=HP_cutoff, h_freq=None)\n",
    "# raw_highpass.compute_psd().plot(average=True)\n",
    "# Remove power line noise\n",
    "AC_freqs = 50 # AC power line frequency\n",
    "row_notch = raw_highpass.copy().notch_filter(freqs=AC_freqs)\n",
    "# row_notch.compute_psd().plot(average=True)\n",
    "# Resampling\n",
    "raw_downsampled = row_notch.copy().resample(sfreq=fsStim)\n",
    "# raw_downsampled.compute_psd().plot(average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load eeg data and sample rate\n",
    "eeg_channel_indices = mne.pick_types(raw_lab.info, eeg=True)\n",
    "eeg_downsampled, times = raw_downsampled[eeg_channel_indices]\n",
    "eeg_downsampled = eeg_downsampled[:,:len(features)].T\n",
    "times = times[:len(features)]\n",
    "normalized_features = zscore(features) # normalize features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCA\n",
    "\n",
    "Run canonical component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_timefilter = fsStim\n",
    "n_components = 5\n",
    "# Find the convolution matrix and run CCA (with all data)\n",
    "conv_mtx = utils.convolution_mtx(L_timefilter, normalized_features)\n",
    "corr_coe, p_value, V_A, V_B = utils.cano_corr(eeg_downsampled, conv_mtx, n_components=n_components)\n",
    "filtered_EEG = eeg_downsampled@V_A\n",
    "filtered_Sti = conv_mtx@V_B\n",
    "print('Note: no unseen data')\n",
    "print('Correlation coefficients of the top {} components: {}'.format(n_components, corr_coe))\n",
    "print('P-values of the top {} components: {}'.format(n_components, p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "fold = 10\n",
    "corr_train = np.zeros((fold, n_components))\n",
    "corr_test = np.zeros((fold, n_components))\n",
    "for idx in range(fold):\n",
    "    EEG_train, EEG_test, Sti_train, Sti_test = utils.split(eeg_downsampled, normalized_features, fold=fold, fold_idx=idx+1)\n",
    "    conv_mtx_train = utils.convolution_mtx(L_timefilter, Sti_train)\n",
    "    corr_train[idx,:], p_value_train, V_A_train, V_B_train = utils.cano_corr(EEG_train, conv_mtx_train, n_components=n_components)\n",
    "    conv_mtx_test = utils.convolution_mtx(L_timefilter, Sti_test)\n",
    "    corr_test[idx,:], p_value_test, _, _ = utils.cano_corr(EEG_test, conv_mtx_test, n_components=n_components, V_A=V_A_train, V_B=V_B_train)\n",
    "print('Average correlation coefficients of the top {} components on the training sets: {}'.format(n_components, np.average(corr_train, axis=0)))\n",
    "print('Average correlation coefficients of the top {} components on the test sets: {}'.format(n_components, np.average(corr_test, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations of component 1\n",
    "plt.close()\n",
    "compo = 1\n",
    "ax1 = plt.subplot(411)\n",
    "ax1.plot(times, features)\n",
    "ax1.title.set_text('Features')\n",
    "ax2 = plt.subplot(412, sharex = ax1)\n",
    "ax2.plot(times, eeg_downsampled[:,0])\n",
    "ax2.title.set_text('EEG signals (of channel Fp1)')\n",
    "ax3 = plt.subplot(413, sharex = ax1)\n",
    "ax3.plot(times, filtered_Sti[:,compo-1])\n",
    "ax3.title.set_text('Filtered features (1st component)')\n",
    "ax4 = plt.subplot(414, sharex = ax1)\n",
    "ax4.plot(times, filtered_EEG[:,compo-1])\n",
    "ax4.title.set_text('Filtered EEG signals (1st component)')\n",
    "ax4.set_xlabel('time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_B[:,compo-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(range(len(V_B[:,compo-1])), V_B[:,compo-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filtered vs single channel EEG: The eye blink artifacts have been suppressed\n",
    "- Filtered vs unfiltered features: Shapes are similar; Filtered features are smoother (triangle filter)\n",
    "- Filtered features and filtered EEG: Peaks are aligned\n",
    "\n",
    "Note: peaks in features occur when there are scene shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations of component 2\n",
    "plt.close()\n",
    "compo = 2\n",
    "ax1 = plt.subplot(411)\n",
    "ax1.plot(times, features)\n",
    "ax1.title.set_text('Features')\n",
    "ax2 = plt.subplot(412, sharex = ax1)\n",
    "ax2.plot(times, eeg_downsampled[:,0])\n",
    "ax2.title.set_text('EEG signals (of channel Fp1)')\n",
    "ax3 = plt.subplot(413, sharex = ax1)\n",
    "ax3.plot(times, filtered_Sti[:,compo-1])\n",
    "ax3.title.set_text('Filtered features (2nd component)')\n",
    "ax4 = plt.subplot(414, sharex = ax1)\n",
    "ax4.plot(times, filtered_EEG[:,compo-1])\n",
    "ax4.title.set_text('Filtered EEG signals (2nd component)')\n",
    "ax4.set_xlabel('time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_B[:,compo-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(range(len(V_B[:,compo-1])), V_B[:,compo-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filtered vs single channel EEG: The eye blink artifacts have been suppressed; Peaks are not easily distinguishable\n",
    "- Filtered vs unfiltered features: Filtered features capture the 1st order information of the original features\n",
    "- Filtered features and filtered EEG: The alignment of the peaks is not very significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = times[1]-times[0]\n",
    "grad = np.gradient(np.squeeze(features), dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "compo = 2\n",
    "ax1 = plt.subplot(311)\n",
    "ax1.plot(times, features)\n",
    "ax1.title.set_text('Features')\n",
    "ax2 = plt.subplot(312, sharex = ax1)\n",
    "ax2.plot(times, filtered_Sti[:,compo-1])\n",
    "ax2.title.set_text('Filtered features (2nd component)')\n",
    "ax3 = plt.subplot(313, sharex = ax1)\n",
    "ax3.plot(times, grad)\n",
    "ax3.title.set_text('Gradients of the features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_grad = np.gradient(grad, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compo = 3\n",
    "plt.close()\n",
    "ax1 = plt.subplot(211)\n",
    "ax1.plot(times, filtered_Sti[:,compo-1])\n",
    "ax1.title.set_text('Filtered features (3rd component)')\n",
    "ax2 = plt.subplot(212, sharex = ax1)\n",
    "ax2.plot(times, grad_grad)\n",
    "ax2.title.set_text('2nd order derivative of the features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_B[:,compo-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(range(len(V_B[:,compo-1])), V_B[:,compo-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_3 = np.gradient(grad_grad, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compo = 4\n",
    "plt.close()\n",
    "ax1 = plt.subplot(211)\n",
    "ax1.plot(times, filtered_Sti[:,compo-1])\n",
    "ax1.title.set_text('Filtered features (4th component)')\n",
    "ax2 = plt.subplot(212, sharex = ax1)\n",
    "ax2.plot(times, grad_3)\n",
    "ax2.title.set_text('3rd order derivative of the features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_B[:,compo-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(range(len(V_B[:,compo-1])), V_B[:,compo-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4780ce94013b4ad826834d504b051d615119766f3ac7f8bac99efc1ee879921"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
