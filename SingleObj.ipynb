{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "from findpeaks import findpeaks\n",
    "from numpy import linalg as LA\n",
    "from scipy.stats import zscore, pearsonr\n",
    "from scipy.io import savemat, loadmat\n",
    "from scipy import signal\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_features(feats, smooth=True, objflow=True):\n",
    "    y = copy.deepcopy(feats)\n",
    "    if not objflow:\n",
    "        # discard the coordinate of the center if it is not object detection based optical flow \n",
    "        y = y[:,:-2]\n",
    "    else:\n",
    "        # recover unnormalized histogram\n",
    "        # TODO: remove in the future version\n",
    "        y[:,0:8] = y[:,0:8] * np.expand_dims(y[:,8], axis=1)\n",
    "    # interpolate NaN values (linealy)\n",
    "    T, nb_feature = y.shape\n",
    "    for i in range(nb_feature):\n",
    "        # interpolate NaN values\n",
    "        nans, x= np.isnan(y[:,i]), lambda z: z.nonzero()[0]\n",
    "        if any(nans):\n",
    "            f1 = scipy.interpolate.interp1d(x(~nans), y[:,i][~nans], fill_value='extrapolate')\n",
    "            y[:,i][nans] = f1(x(nans))\n",
    "        if smooth and i < (nb_feature-2): # don't smooth coordinates of the center\n",
    "            # extract envelope by finding peaks and interpolating peaks with spline\n",
    "            idx_peaks = scipy.signal.find_peaks(y[:,i])[0]\n",
    "            idx_rest = np.setdiff1d(np.array(range(T)), idx_peaks)\n",
    "            f2 = scipy.interpolate.interp1d(idx_peaks, y[:,i][idx_peaks], kind='cubic', fill_value='extrapolate')\n",
    "            y[:,i][idx_rest] = f2(idx_rest)\n",
    "    return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multisub_data_org(subjects, video_id, folder, fsStim, bads=[], eog=False, regression=False, normalize=True, smooth=True, objflow=True):\n",
    "    feats_path_folder = '../Feature extraction/features/'\n",
    "    if objflow:\n",
    "        feats_path = feats_path_folder + video_id + '_feats.npy'\n",
    "    else:\n",
    "        feats_path = feats_path_folder + video_id + '_flow.npy'\n",
    "    feats = np.load(feats_path)\n",
    "    feats = clean_features(feats, smooth=smooth, objflow=objflow)\n",
    "    T = feats.shape[0]\n",
    "    eeg_list = []\n",
    "    for sub in subjects:\n",
    "        eeg_path = '../../Experiments/data/'+ sub +'/' + folder + '/' + video_id + '_eeg.set'\n",
    "        eeg_prepro, fs = utils.preprocessing(eeg_path, HP_cutoff = 0.5, AC_freqs=50, resamp_freqs=fsStim, bads=bads, eog=eog, regression=regression, normalize=normalize)\n",
    "        eeg_channel_indices = mne.pick_types(eeg_prepro.info, eeg=True)\n",
    "        eeg_downsampled, _ = eeg_prepro[eeg_channel_indices]\n",
    "        eeg_downsampled = eeg_downsampled.T\n",
    "        eeg_list.append(eeg_downsampled)\n",
    "        if eeg_downsampled.shape[0] < T:\n",
    "            T = eeg_downsampled.shape[0]\n",
    "    # Clip data\n",
    "    feats = feats[2*fsStim:T, :]\n",
    "    eeg_list = [np.expand_dims(eeg[2*fsStim:T,:], axis=2) for eeg in eeg_list]\n",
    "    eeg_multisub = np.concatenate(tuple(eeg_list), axis=2)\n",
    "    times = np.array(range(T))/fs\n",
    "    return feats, eeg_multisub, fs, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "subjects = ['AS', 'YY']\n",
    "folder = 'Single_obj'\n",
    "eeg_path_folder = \"../../Experiments/data/AS/Single_obj/\"\n",
    "video_ids = [dataset[0:2] for dataset in os.listdir(eeg_path_folder) if dataset.endswith('.set')]\n",
    "# video_ids = ['01', '02', '04', '05', '06', '08', '09', '14', '16']\n",
    "# video_ids = ['16']\n",
    "features_list = []\n",
    "eeg_multisub_list = []\n",
    "for video_id in video_ids:\n",
    "    features, eeg_multisub, fs, _ = multisub_data_org(subjects, video_id, folder, fsStim=30, bads=['B25'], eog=True, regression=True, normalize=True, smooth=True, objflow=True)\n",
    "    # Or do a normalization here\n",
    "    # features[:,8] = features[:,8]/LA.norm(features[:,8])\n",
    "    features_list.append(features) \n",
    "    eeg_multisub_list.append(eeg_multisub)\n",
    "feature_concat = np.concatenate(tuple(features_list), axis=0)\n",
    "# feature_concat = feature_concat/LA.norm(feature_concat)\n",
    "eeg_multisub_concat = np.concatenate(tuple(eeg_multisub_list), axis=0)\n",
    "T = feature_concat.shape[0]\n",
    "times = np.array(range(T))/fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = feature_concat[:,0:8]\n",
    "mag_avg = np.expand_dims(feature_concat[:,8], axis=1)\n",
    "mag_up = np.expand_dims(feature_concat[:,9], axis=1)\n",
    "mag_down = np.expand_dims(feature_concat[:,10], axis=1)\n",
    "mag_left = np.expand_dims(feature_concat[:,11], axis=1)\n",
    "mag_right = np.expand_dims(feature_concat[:,12], axis=1)\n",
    "mag_all = feature_concat[:,8:13]\n",
    "center = feature_concat[:,13:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(mag_avg)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: non-causal temporal filter \n",
    "n_components = 5\n",
    "fold = 10\n",
    "eeg_onesub = eeg_multisub_concat[:,:,0]\n",
    "corr_train, corr_test, V_A_train, V_B_train = utils.cross_val_CCA(eeg_onesub, mag_avg, fs, L_EEG=1, L_feat=fs+1, causalx=False, causaly=False, fold=10, n_components=5, regularization='lwcov', K_regu=None, message=True, signifi_level=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: causal temporal filter \n",
    "# Note: GCCA-one subject + stimulus = CCA\n",
    "datalist = [eeg_multisub_concat[:,:,0], mag_avg]\n",
    "Llist = [1, fs+1]\n",
    "causal_list = [False, False]\n",
    "rhos= [1, 1]\n",
    "corr_train, corr_test, Wlist_train, Flist_train = utils.cross_val_GCCA_multi_mod(datalist, Llist, causal_list, rhos, fs, fold=10, n_components=5, regularization='lwcov', message=True, signifi_level=True, ISC=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization:\n",
    "forward_model = utils.forward_model(eeg_multisub_concat[:,:,1], V_A_train)\n",
    "biosemi_layout = mne.channels.read_layout('biosemi')\n",
    "create_info = mne.create_info(biosemi_layout.names, ch_types='eeg', sfreq=30)\n",
    "create_info.set_montage('biosemi64')\n",
    "plt.close()\n",
    "plt.figure()\n",
    "# plt.figure(figsize=(20, 20))\n",
    "for i in range(5):\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    mne.viz.plot_topomap(forward_model[:,i], create_info, ch_type='eeg', axes=ax)\n",
    "    ax.set_title('CC '+str(i+1))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCCA-all subjects\n",
    "datalist = [eeg_multisub_concat]\n",
    "Llist = [1]\n",
    "causal_list = [False]\n",
    "rhos = [1]\n",
    "corr_train, corr_test, Wlist_train, Flist_train = utils.cross_val_GCCA_multi_mod(datalist, Llist, causal_list, rhos, fs, fold=10, n_components=5, regularization='lwcov', message=True, signifi_level=True, ISC=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCCA-all subjects + stimulus\n",
    "datalist = [eeg_multisub_concat, mag_avg]\n",
    "Llist = [1, fs+1]\n",
    "causal_list = [False, False]\n",
    "rhos = utils.rho_sweep(datalist, np.linspace(-2,3,11), Llist, causal_list, fs, fold=10, n_components=5, message=True)\n",
    "corr_train, corr_test, Wlist_train, Flist_train = utils.cross_val_GCCA_multi_mod(datalist, Llist, causal_list, rhos, fs, fold=10, n_components=5, regularization='lwcov', message=True, signifi_level=True, ISC=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:30:19) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4780ce94013b4ad826834d504b051d615119766f3ac7f8bac99efc1ee879921"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
