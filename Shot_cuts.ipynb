{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import utils\n",
    "import algo\n",
    "import copy\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from numpy import linalg as LA\n",
    "from scipy import signal\n",
    "from scipy.linalg import toeplitz\n",
    "from scipy.stats import zscore, pearsonr\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from tqdm import tqdm\n",
    "%matplotlib widget"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multisub_data_org(subjects, video_id, fsStim, bads, mask=False, band=None, eog=True, regression=True, normalize=True):\n",
    "    feats_path_folder = '../Feature extraction/features/'\n",
    "    if mask:\n",
    "        feats_path = feats_path_folder + video_id + '_mask.npy'\n",
    "    else:\n",
    "        feats_path = feats_path_folder + video_id + '_flow.npy'\n",
    "    feats = np.load(feats_path)\n",
    "    tempctra = np.load(feats_path_folder + video_id + '_tempctra.npy')\n",
    "    # Discard box info and concatenate tempctra\n",
    "    # feats: histogram of flow + mag/up/down/left/right + absTC/sqTC/muTC\n",
    "    feats = np.concatenate((feats[:,:-4], tempctra), axis=1)\n",
    "    T = feats.shape[0]\n",
    "    eeg_list = []\n",
    "    hf_list = []\n",
    "    eog_list = []\n",
    "    N = len(subjects)\n",
    "    for n in range(N):\n",
    "        eeg_path = '../../Experiments/data/'+ subjects[n] +'/' + video_id + '_eeg.set'\n",
    "        eeg_prepro, fs, high_freq = utils.preprocessing(eeg_path, HP_cutoff = 0.5, AC_freqs=50, band=band, resamp_freqs=fsStim, bads=bads[n], eog=eog, regression=regression, normalize=normalize)\n",
    "        eeg_channel_indices = mne.pick_types(eeg_prepro.info, eeg=True)\n",
    "        eog_channel_indices = mne.pick_types(eeg_prepro.info, eog=True)\n",
    "        eeg_downsampled, _ = eeg_prepro[eeg_channel_indices]\n",
    "        eog_downsampled, _ = eeg_prepro[eog_channel_indices]\n",
    "        eeg_downsampled = eeg_downsampled.T\n",
    "        eog_downsampled = eog_downsampled.T\n",
    "        eeg_list.append(eeg_downsampled)\n",
    "        eog_list.append(eog_downsampled)\n",
    "        if eeg_downsampled.shape[0] < T:\n",
    "            T = eeg_downsampled.shape[0]\n",
    "        hf_indices = mne.pick_types(high_freq.info, eeg=True)\n",
    "        hf_downsampled, _ = high_freq[hf_indices]\n",
    "        hf_downsampled = hf_downsampled.T\n",
    "        hf_list.append(hf_downsampled)\n",
    "        if hf_downsampled.shape[0] < T:\n",
    "            T = hf_downsampled.shape[0] \n",
    "    # Clip data\n",
    "    feats = feats[fsStim:T-fsStim, :]\n",
    "    eeg_list = [np.expand_dims(eeg[fsStim:T-fsStim,:], axis=2) for eeg in eeg_list]\n",
    "    eog_list = [np.expand_dims(eog[fsStim:T-fsStim,:], axis=2) for eog in eog_list]\n",
    "    hf_list = [np.expand_dims(eeg[fsStim:T-fsStim,:], axis=2) for eeg in hf_list]\n",
    "    eeg_multisub = np.concatenate(tuple(eeg_list), axis=2)\n",
    "    eog_multisub = np.concatenate(tuple(eog_list), axis=2)\n",
    "    hf_multisub = np.concatenate(tuple(hf_list), axis=2)\n",
    "    times = np.array(range(T))/fs\n",
    "    return feats, eeg_multisub, eog_multisub, hf_multisub, fs, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "subjects = ['VC','HV','JC','DV','CD','JV','AD','KY']\n",
    "bads = [['B25','B31'],['B25','B31','A20','A21','A26','A31'],['B25','B31','B32','A28','A29','A30'],['A25','A30','B25','B29'],['A30','B25','B31'],['A30','B25'],['B25','B28'],[]]\n",
    "video_id = 'Mr'\n",
    "features, eeg_multisub, eog_multisub, hf_multisub, fs, _ = multisub_data_org(subjects, video_id, fsStim=30, bads=bads, band=[25,35], eog=True, regression=True, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sub = len(subjects)\n",
    "features[:,15] = np.abs(features[:,15])\n",
    "features_smooth = utils.clean_features(features, smooth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of the video (min):', features.shape[0]/30/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(features_smooth[:,8]/LA.norm(features_smooth[:,8]), label='flow')\n",
    "plt.plot(features_smooth[:,13]/LA.norm(features_smooth[:,13]), label='abs temporal contrast')\n",
    "# plt.plot(features_smooth[:,14]/LA.norm(features_smooth[:,14]), label='Sq temporal contrast')\n",
    "# plt.plot(features_smooth[:,15]/LA.norm(features_smooth[:,15]), label='temporal contrast')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep shot cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pip_CCA(eeg_multisub, feature, fs, n_sub, fig_name, tab_name, L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=True, n_components=5):\n",
    "    cc = np.zeros((n_sub, n_components+3))\n",
    "    for id_sub in range(n_sub):\n",
    "        print('subject: ', id_sub+1)\n",
    "        eeg_onesub_list = [eeg_multisub[:,:,id_sub]]\n",
    "        CCA = algo.CanonicalCorrelationAnalysis(eeg_onesub_list, [feature], fs, L_EEG, L_Stim, offset_EEG, offset_Stim, signifi_level=signifi_level, n_components=n_components)\n",
    "        _, corr_test, sig_corr, _, tsc_test, _, _, V_A_train, V_B_train = CCA.cross_val()\n",
    "        cc[id_sub,0] = int(id_sub+1)\n",
    "        cc[id_sub,1:n_components+1] = np.average(corr_test, axis=0)\n",
    "        cc[id_sub,-2] = np.average(tsc_test)\n",
    "        cc[id_sub,-1] = sig_corr\n",
    "        eeg_onesub = np.concatenate(tuple(eeg_onesub_list), axis=0)\n",
    "        forward_model = CCA.forward_model(eeg_onesub, V_A_train)\n",
    "        # if CCA/MrBean does not exist, create it\n",
    "        if not os.path.exists('figures/CCA/MrBean'):\n",
    "            os.makedirs('figures/CCA/MrBean')\n",
    "        utils.plot_spatial_resp(forward_model, corr_test, 'figures/CCA/MrBean/'+fig_name+str(id_sub+1)+'.png')\n",
    "    columns = ['ID'] + ['CC'+str(i+1) for i in range(n_components)] + ['TSC(top2)','Sig_corr']\n",
    "    df_cca = pd.DataFrame(cc, columns = columns)\n",
    "    if not os.path.exists('tables/CCA/MrBean'):\n",
    "        os.makedirs('tables/CCA/MrBean')\n",
    "    df_cca.to_csv('tables/CCA/MrBean/'+tab_name+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_flow = features_smooth[:,8]\n",
    "pip_CCA(eeg_multisub, avg_flow, fs, n_sub, 'SR_avgflow_', 'avgflow_eeg', L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=True, n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tempctr = features_smooth[:,13]\n",
    "pip_CCA(eeg_multisub, avg_tempctr, fs, n_sub, 'SR_avgtempctr_', 'avgtempctr_eeg', L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=True, n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_onesub_list = [eeg_multisub[:,:,2]]\n",
    "CCA = algo.CanonicalCorrelationAnalysis(eeg_onesub_list, [avg_flow], fs, L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=False, n_components=2)\n",
    "_, corr_test, sig_corr, _, tsc_test, _, _, V_A_train, V_B_train = CCA.cross_val()\n",
    "eeg_onesub = np.concatenate(tuple(eeg_onesub_list), axis=0)\n",
    "forward_model = CCA.forward_model(eeg_onesub, V_A_train)\n",
    "utils.plot_spatial_resp(forward_model, corr_test, '../../Manuscript/1st/images/avgflow_eeg.png', fig_size=(6,2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_onesub_list = [eeg_multisub[:,:,2]]\n",
    "CCA = algo.CanonicalCorrelationAnalysis(eeg_onesub_list, [avg_tempctr], fs, L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=False, n_components=2)\n",
    "_, corr_test, sig_corr, _, tsc_test, _, _, V_A_train, V_B_train = CCA.cross_val()\n",
    "eeg_onesub = np.concatenate(tuple(eeg_onesub_list), axis=0)\n",
    "forward_model = CCA.forward_model(eeg_onesub, V_A_train)\n",
    "utils.plot_spatial_resp(forward_model, corr_test, '../../Manuscript/1st/images/avgtempctr_eeg.png', fig_size=(6,2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_onesub_list = [eeg_multisub[:,:,2]]\n",
    "CCA = algo.CanonicalCorrelationAnalysis(eeg_onesub_list, [binary_sc], fs, L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=False, n_components=2)\n",
    "_, corr_test, sig_corr, _, tsc_test, _, _, V_A_train, V_B_train = CCA.cross_val()\n",
    "eeg_onesub = np.concatenate(tuple(eeg_onesub_list), axis=0)\n",
    "forward_model = CCA.forward_model(eeg_onesub, V_A_train)\n",
    "utils.plot_spatial_resp(forward_model, corr_test, '../../Manuscript/1st/images/binary_eeg.png', fig_size=(6,2.5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove shot cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find shot cuts based on the peaks of (normalized) avgflow\n",
    "avgflow_norm = features[:,8]/LA.norm(features[:,8])\n",
    "peak, _ = signal.find_peaks(avgflow_norm, prominence=(0.02, None), distance=fs, width=(None, 1.5))\n",
    "plt.close()\n",
    "plt.plot(range(len(avgflow_norm)), avgflow_norm)\n",
    "plt.plot(peak, avgflow_norm[peak], \"x\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get handcrafted binary shot cut features\n",
    "binary_sc = np.zeros_like(avgflow_norm)\n",
    "binary_sc[peak] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "time_axis = np.array(range(len(avgflow_norm)))/fs\n",
    "plt.plot(time_axis, binary_sc, figure=plt.figure(figsize=(6, 2.5)))\n",
    "xlabel = 'Time (s)'\n",
    "ylabel = 'Binary shot cut feature'\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('../../Manuscript/1st/images/binary.png', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_CCA(eeg_multisub, binary_sc, fs, n_sub, 'SR_binary_', 'binary_eeg', L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=True, n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1s before and after the peaks will be removed\n",
    "nearby_idx = []\n",
    "for p in peak:\n",
    "    nearby_idx = nearby_idx + list(range(max(0, p-30), min(p+30, len(avgflow_norm))))\n",
    "nearby_idx = list(set(nearby_idx))\n",
    "features_clean = utils.clean_features(np.delete(features, nearby_idx, axis=0), smooth=True)\n",
    "EEG_clean = np.delete(eeg_multisub, nearby_idx, axis=0)\n",
    "EOG_clean = np.delete(eog_multisub, nearby_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgflow_clean = features_clean[:,8]\n",
    "pip_CCA(EEG_clean, avgflow_clean, fs, n_sub, 'SR_avgflow_clean_', 'avgflow_clean_eeg', L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=True, n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgtempctr_clean = features_clean[:,13]\n",
    "pip_CCA(EEG_clean, avgtempctr_clean, fs, n_sub, 'SR_avgtempctr_clean_', 'avgtempctr_clean_eeg', L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=True, n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features between two shot cuts\n",
    "# features_normalized = copy.deepcopy(features)\n",
    "# idx_start = 0\n",
    "# for p in peak:\n",
    "#     idx_end = p\n",
    "#     features_normalized[idx_start+1:idx_end, :] = features[idx_start+1:idx_end, :]/LA.norm(features[idx_start+1:idx_end, :], axis=0)\n",
    "#     idx_start = p\n",
    "# features_normalized[idx_start+1:, :] = features[idx_start+1:, :]/LA.norm(features[idx_start+1:, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Don't delete but interpolate\n",
    "# features_nonan = utils.clean_features(features, smooth=False)\n",
    "# nb_features = features_nonan.shape[1]\n",
    "# for i in range(nb_features):\n",
    "#     for p in peak:\n",
    "#         x = np.array([p-2, p-1, p+1, p+2])\n",
    "#         y = np.array([features_nonan[p-2,i], features_nonan[p-1,i], features_nonan[p+1,i], features_nonan[p+2,i]])\n",
    "#         xnew = np.array([p-2, p-1, p, p+1, p+2])\n",
    "#         ynew = np.interp(xnew, x, y)\n",
    "#         features_nonan[p,i] = ynew[2]\n",
    "# features_interp = utils.clean_features(features_nonan, smooth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CorrCA/GCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_CA = algo.CorrelatedComponentAnalysis([eeg_multisub], fs, L=5, offset=2, signifi_level=True, n_components=10)\n",
    "corr_train, corr_test, tsc_train, tsc_test, isc_train, isc_test, W_train, F_train = corr_CA.cross_val()\n",
    "if not os.path.exists('figures/CorrCA/MrBean'):\n",
    "    os.makedirs('figures/CorrCA/MrBean')\n",
    "utils.plot_spatial_resp(F_train, corr_test, 'figures/CorrCA/MrBean/'+str(n_sub)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_CA = algo.CorrelatedComponentAnalysis([EEG_clean], fs, L=5, offset=2, signifi_level=True, n_components=10)\n",
    "corr_train, corr_test, tsc_train, tsc_test, isc_train, isc_test, W_train, F_train = corr_CA.cross_val()\n",
    "utils.plot_spatial_resp(F_train, corr_test, 'figures/CorrCA/MrBean/clean_'+str(n_sub)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCCA = algo.GeneralizedCCA([eeg_multisub], fs, L=5, offset=2, n_components=10, signifi_level=True)\n",
    "corr_train, corr_test, tsc_train, tsc_test, dist_train, dist_test, W_train, F_train = GCCA.cross_val()\n",
    "if not os.path.exists('figures/GCCA/MrBean'):\n",
    "    os.makedirs('figures/GCCA/MrBean')\n",
    "utils.plot_spatial_resp(F_train, corr_test, 'figures/GCCA/MrBean/'+str(n_sub)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCCA = algo.GeneralizedCCA([EEG_clean], fs, L=5, offset=2, n_components=10, signifi_level=True)\n",
    "corr_train, corr_test, tsc_train, tsc_test, dist_train, dist_test, W_train, F_train = GCCA.cross_val()\n",
    "if not os.path.exists('figures/GCCA/MrBean'):\n",
    "    os.makedirs('figures/GCCA/MrBean')\n",
    "utils.plot_spatial_resp(F_train, corr_test, 'figures/GCCA/MrBean/clean_'+str(n_sub)+'.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CorrCA/GCCA + LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pip_GCCA_LS(eeg_multisub, feature, n_sub, tab_name, ifcorrca, L_EEG=5, L_Stim=int(fs/2), offset_EEG=2, offset_Stim=0, id_sub=0, n_components=10):\n",
    "    LSGCCA = algo.LSGCCA([eeg_multisub], [feature], fs, L_EEG, L_Stim, offset_EEG, offset_Stim, id_sub=0, corrca=ifcorrca, n_components=n_components)\n",
    "    LSGCCA.to_latent_space()\n",
    "    cc = np.zeros((n_sub, n_components+2))\n",
    "    for id_sub in range(n_sub):\n",
    "        print('subject: ', id_sub+1)\n",
    "        LSGCCA.id_sub = id_sub\n",
    "        _, corr_test, sig_corr, We_train, Ws_train, F_train = LSGCCA.cross_val()\n",
    "        cc[id_sub,0] = int(id_sub+1)\n",
    "        cc[id_sub,1:n_components+1] = np.average(corr_test, axis=0)\n",
    "        cc[id_sub,-1] = sig_corr\n",
    "    columns = ['ID'] + ['CC'+str(i+1) for i in range(n_components)] + ['Sig_corr']\n",
    "    df_cca = pd.DataFrame(cc, columns = columns)\n",
    "    if not os.path.exists('tables/GCCA_LS/MrBean'):\n",
    "        os.makedirs('tables/GCCA_LS/MrBean')\n",
    "    df_cca.to_csv('tables/GCCA_LS/MrBean/'+tab_name+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_GCCA_LS(eeg_multisub, binary_sc, n_sub, 'CorrCA_binary', ifcorrca=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_GCCA_LS(eeg_multisub, binary_sc, n_sub, 'GCCA_binary', ifcorrca=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4780ce94013b4ad826834d504b051d615119766f3ac7f8bac99efc1ee879921"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
