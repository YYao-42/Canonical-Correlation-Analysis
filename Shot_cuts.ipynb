{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import utils\n",
    "import algo\n",
    "import copy\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from numpy import linalg as LA\n",
    "from scipy import signal\n",
    "from scipy.linalg import toeplitz\n",
    "from scipy.stats import zscore, pearsonr\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from tqdm import tqdm\n",
    "%matplotlib widget"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multisub_data_org(subjects, video_id, fsStim, bads, mask=False, band=None, eog=True, regression=True, normalize=True):\n",
    "    feats_path_folder = '../Feature extraction/features/'\n",
    "    if mask:\n",
    "        feats_path = feats_path_folder + video_id + '_mask.npy'\n",
    "    else:\n",
    "        feats_path = feats_path_folder + video_id + '_flow.npy'\n",
    "    feats = np.load(feats_path)\n",
    "    tempctra = np.load(feats_path_folder + video_id + '_tempctra.npy')\n",
    "    # Discard box info and concatenate tempctra\n",
    "    # feats: histogram of flow + mag/up/down/left/right + absTC/sqTC/muTC\n",
    "    feats = np.concatenate((feats[:,:-4], tempctra), axis=1)\n",
    "    T = feats.shape[0]\n",
    "    eeg_list = []\n",
    "    hf_list = []\n",
    "    eog_list = []\n",
    "    N = len(subjects)\n",
    "    for n in range(N):\n",
    "        eeg_path = '../../Experiments/data/'+ subjects[n] +'/' + video_id + '_eeg.set'\n",
    "        eeg_prepro, fs, high_freq = utils.preprocessing(eeg_path, HP_cutoff = 0.5, AC_freqs=50, band=band, resamp_freqs=fsStim, bads=bads[n], eog=eog, regression=regression, normalize=normalize)\n",
    "        eeg_channel_indices = mne.pick_types(eeg_prepro.info, eeg=True)\n",
    "        eog_channel_indices = mne.pick_types(eeg_prepro.info, eog=True)\n",
    "        eeg_downsampled, _ = eeg_prepro[eeg_channel_indices]\n",
    "        eog_downsampled, _ = eeg_prepro[eog_channel_indices]\n",
    "        eeg_downsampled = eeg_downsampled.T\n",
    "        eog_downsampled = eog_downsampled.T\n",
    "        eeg_list.append(eeg_downsampled)\n",
    "        eog_list.append(eog_downsampled)\n",
    "        if eeg_downsampled.shape[0] < T:\n",
    "            T = eeg_downsampled.shape[0]\n",
    "        hf_indices = mne.pick_types(high_freq.info, eeg=True)\n",
    "        hf_downsampled, _ = high_freq[hf_indices]\n",
    "        hf_downsampled = hf_downsampled.T\n",
    "        hf_list.append(hf_downsampled)\n",
    "        if hf_downsampled.shape[0] < T:\n",
    "            T = hf_downsampled.shape[0] \n",
    "    # Clip data\n",
    "    feats = feats[fsStim:T-fsStim, :]\n",
    "    eeg_list = [np.expand_dims(eeg[fsStim:T-fsStim,:], axis=2) for eeg in eeg_list]\n",
    "    eog_list = [np.expand_dims(eog[fsStim:T-fsStim,:], axis=2) for eog in eog_list]\n",
    "    hf_list = [np.expand_dims(eeg[fsStim:T-fsStim,:], axis=2) for eeg in hf_list]\n",
    "    eeg_multisub = np.concatenate(tuple(eeg_list), axis=2)\n",
    "    eog_multisub = np.concatenate(tuple(eog_list), axis=2)\n",
    "    hf_multisub = np.concatenate(tuple(hf_list), axis=2)\n",
    "    times = np.array(range(T))/fs\n",
    "    return feats, eeg_multisub, eog_multisub, hf_multisub, fs, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# subjects = ['VC','HV','JC','DV','CD','JV','AD','KY','KB','SC']\n",
    "# bads = [['B25','B31'],['B25','B31','A20','A21','A26','A31'],['B25','B31','B32','A28','A29','A30'],['A25','A30','B25','B29'],['A30','B25','B31'],['A30','B25'],['B25','B28'],[],['B25'],['B25']]\n",
    "# video_id = 'Mr'\n",
    "# features, eeg_multisub, eog_multisub, hf_multisub, fs, _ = multisub_data_org(subjects, video_id, fsStim=30, bads=bads, band=[25,35], eog=True, regression=True, normalize=True)\n",
    "# if not os.path.exists('data/MrBean'):\n",
    "#     os.makedirs('data/MrBean')\n",
    "# with open('data/MrBean/features.pkl', 'wb') as f:\n",
    "#     pickle.dump(features, f)\n",
    "# with open('data/MrBean/eeg_multisub.pkl', 'wb') as f:\n",
    "#     pickle.dump(eeg_multisub, f)\n",
    "# with open('data/MrBean/eog_multisub.pkl', 'wb') as f:\n",
    "#     pickle.dump(eog_multisub, f)\n",
    "# with open('data/MrBean/hf_multisub.pkl', 'wb') as f:\n",
    "#     pickle.dump(hf_multisub, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['VC','HV','JC','DV','CD','JV','AD','KY','KB','SC']\n",
    "fs = 30\n",
    "with open('data/MrBean/features.pkl', 'rb') as f:\n",
    "    features = pickle.load(f)\n",
    "with open('data/MrBean/eeg_multisub.pkl', 'rb') as f:\n",
    "    eeg_multisub = pickle.load(f)\n",
    "with open('data/MrBean/eog_multisub.pkl', 'rb') as f:\n",
    "    eog_multisub = pickle.load(f)\n",
    "with open('data/MrBean/hf_multisub.pkl', 'rb') as f:\n",
    "    hf_multisub = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sub = len(subjects)\n",
    "features[:,15] = np.abs(features[:,15])\n",
    "features_smooth = utils.clean_features(features, smooth=True)\n",
    "avg_flow = features_smooth[:,8]\n",
    "avg_tempctr = features_smooth[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of the video (min):', features.shape[0]/30/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(features_smooth[:,8]/LA.norm(features_smooth[:,8]), label='flow')\n",
    "plt.plot(features_smooth[:,13]/LA.norm(features_smooth[:,13]), label='abs temporal contrast')\n",
    "# plt.plot(features_smooth[:,14]/LA.norm(features_smooth[:,14]), label='Sq temporal contrast')\n",
    "# plt.plot(features_smooth[:,15]/LA.norm(features_smooth[:,15]), label='temporal contrast')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep shot cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pip_CCA(eeg_multisub, feature, fs, n_sub, fig_name, tab_name, L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=True, n_components=5):\n",
    "    cc = np.zeros((n_sub, n_components+3))\n",
    "    for id_sub in range(n_sub):\n",
    "        print('subject: ', id_sub+1)\n",
    "        eeg_onesub_list = [eeg_multisub[:,:,id_sub]]\n",
    "        CCA = algo.CanonicalCorrelationAnalysis(eeg_onesub_list, [feature], fs, L_EEG, L_Stim, offset_EEG, offset_Stim, signifi_level=signifi_level, n_components=n_components)\n",
    "        _, corr_test, sig_corr, _, tsc_test, _, _, V_A_train, V_B_train = CCA.cross_val()\n",
    "        cc[id_sub,0] = int(id_sub+1)\n",
    "        cc[id_sub,1:n_components+1] = np.average(corr_test, axis=0)\n",
    "        cc[id_sub,-2] = np.average(tsc_test)\n",
    "        cc[id_sub,-1] = sig_corr\n",
    "        eeg_onesub = np.concatenate(tuple(eeg_onesub_list), axis=0)\n",
    "        forward_model = CCA.forward_model(eeg_onesub, V_A_train)\n",
    "        # if CCA/MrBean does not exist, create it\n",
    "        if not os.path.exists('figures/CCA/MrBean'):\n",
    "            os.makedirs('figures/CCA/MrBean')\n",
    "        utils.plot_spatial_resp(forward_model, corr_test, 'figures/CCA/MrBean/'+fig_name+str(id_sub+1)+'.png')\n",
    "    columns = ['ID'] + ['CC'+str(i+1) for i in range(n_components)] + ['TSC','Sig_corr']\n",
    "    df_cca = pd.DataFrame(cc, columns = columns)\n",
    "    if not os.path.exists('tables/CCA/MrBean'):\n",
    "        os.makedirs('tables/CCA/MrBean')\n",
    "    df_cca.to_csv('tables/CCA/MrBean/'+tab_name+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_flow = features_smooth[:,8]\n",
    "pip_CCA(eeg_multisub, avg_flow, fs, n_sub, 'SR_avgflow_', 'avgflow_eeg', L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=True, n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tempctr = features_smooth[:,13]\n",
    "pip_CCA(eeg_multisub, avg_tempctr, fs, n_sub, 'SR_avgtempctr_', 'avgtempctr_eeg', L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=True, n_components=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_onesub_list = [eeg_multisub[:,:,2]]\n",
    "CCA = algo.CanonicalCorrelationAnalysis(eeg_onesub_list, [avg_flow], fs, L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=False, n_components=2)\n",
    "_, corr_test, sig_corr, _, tsc_test, _, _, V_A_train, V_B_train = CCA.cross_val()\n",
    "eeg_onesub = np.concatenate(tuple(eeg_onesub_list), axis=0)\n",
    "forward_model = CCA.forward_model(eeg_onesub, V_A_train)\n",
    "utils.plot_spatial_resp(forward_model, corr_test, '../../Manuscript/1st/images/avgflow_eeg_cb.jpeg', fig_size=(6,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_onesub_list = [eeg_multisub[:,:,2]]\n",
    "CCA = algo.CanonicalCorrelationAnalysis(eeg_onesub_list, [avg_tempctr], fs, L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=False, n_components=2)\n",
    "_, corr_test, sig_corr, _, tsc_test, _, _, V_A_train, V_B_train = CCA.cross_val()\n",
    "eeg_onesub = np.concatenate(tuple(eeg_onesub_list), axis=0)\n",
    "forward_model = CCA.forward_model(eeg_onesub, V_A_train)\n",
    "utils.plot_spatial_resp(forward_model, corr_test, '../../Manuscript/1st/images/avgtempctr_eeg_cb.jpeg', fig_size=(6,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this block after binary_sc is defined\n",
    "eeg_onesub_list = [eeg_multisub[:,:,2]]\n",
    "CCA = algo.CanonicalCorrelationAnalysis(eeg_onesub_list, [binary_sc], fs, L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=False, n_components=2)\n",
    "_, corr_test, sig_corr, _, tsc_test, _, _, V_A_train, V_B_train = CCA.cross_val()\n",
    "eeg_onesub = np.concatenate(tuple(eeg_onesub_list), axis=0)\n",
    "forward_model = CCA.forward_model(eeg_onesub, V_A_train)\n",
    "utils.plot_spatial_resp(forward_model, corr_test, '../../Manuscript/1st/images/binary_eeg_cb.jpeg', fig_size=(6,3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove shot cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find shot cuts based on the peaks of (normalized) avgflow\n",
    "avgflow_norm = features[:,8]/LA.norm(features[:,8])\n",
    "# avg_tempctr_norm = features[:,13]/LA.norm(features[:,13])\n",
    "peak, _ = signal.find_peaks(avgflow_norm, prominence=(0.02, None), distance=fs, width=(None, 1.5))\n",
    "plt.close()\n",
    "plt.plot(range(len(avgflow_norm)), avgflow_norm)\n",
    "plt.plot(peak, avgflow_norm[peak], \"x\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_refine = np.delete(peak, peak==271)\n",
    "peak_refine = np.delete(peak_refine, peak_refine==611)\n",
    "peak_refine = np.append(peak_refine, [718, 38171, 38293, 38489, 42440])\n",
    "peak = np.sort(peak_refine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get handcrafted binary shot cut features\n",
    "binary_sc = np.zeros_like(avgflow_norm)\n",
    "binary_sc[peak] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "time_axis = np.array(range(len(avgflow_norm)))/fs\n",
    "plt.plot(time_axis, binary_sc, figure=plt.figure(figsize=(6, 2.5)))\n",
    "xlabel = 'Time (s)'\n",
    "ylabel = 'Binary shot cut feature'\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('../../Manuscript/1st/images/feat_binary.jpeg', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_CCA(eeg_multisub, binary_sc, fs, n_sub, 'SR_binary_', 'binary_eeg', L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=True, n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1s before and after the peaks will be removed\n",
    "nearby_idx = []\n",
    "for p in peak:\n",
    "    nearby_idx = nearby_idx + list(range(max(0, p-30), min(p+30, len(avgflow_norm))))\n",
    "nearby_idx = list(set(nearby_idx))\n",
    "features_clean = utils.clean_features(np.delete(features, nearby_idx, axis=0), smooth=True)\n",
    "EEG_clean = np.delete(eeg_multisub, nearby_idx, axis=0)\n",
    "EOG_clean = np.delete(eog_multisub, nearby_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_clean.shape[0]/30/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgflow_clean = features_clean[:,8]\n",
    "pip_CCA(EEG_clean, avgflow_clean, fs, n_sub, 'SR_avgflow_clean_', 'avgflow_clean_eeg', L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=True, n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgtempctr_clean = features_clean[:,13]\n",
    "pip_CCA(EEG_clean, avgtempctr_clean, fs, n_sub, 'SR_avgtempctr_clean_', 'avgtempctr_clean_eeg', L_EEG=3, L_Stim=int(fs/2), offset_EEG=1, offset_Stim=0, signifi_level=True, n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CorrCA/GCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_CA = algo.CorrelatedComponentAnalysis([eeg_multisub], fs, L=5, offset=2, signifi_level=True, n_components=10)\n",
    "corr_train, corr_test, cov_train, cov_test, tsc_train, tsc_test, isc_train, isc_test, W_train, F_train = corr_CA.cross_val()\n",
    "if not os.path.exists('figures/CorrCA/MrBean'):\n",
    "    os.makedirs('figures/CorrCA/MrBean')\n",
    "utils.plot_spatial_resp(F_train, corr_test, 'figures/CorrCA/MrBean/'+str(n_sub)+'_cb.pdf', ifISC=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_CA = algo.CorrelatedComponentAnalysis([EEG_clean], fs, L=5, offset=2, signifi_level=True, n_components=10)\n",
    "corr_train, corr_test, cov_train, cov_test, tsc_train, tsc_test, isc_train, isc_test, W_train, F_train = corr_CA.cross_val()\n",
    "utils.plot_spatial_resp(F_train, corr_test, 'figures/CorrCA/MrBean/clean_'+str(n_sub)+'_cb.pdf', ifISC=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCCA = algo.GeneralizedCCA([eeg_multisub], fs, L=5, offset=2, n_components=10, signifi_level=True)\n",
    "corr_train, corr_test, cov_train, cov_test, tsc_train, tsc_test, dist_train, dist_test, W_train, F_train = GCCA.cross_val()\n",
    "if not os.path.exists('figures/GCCA/MrBean'):\n",
    "    os.makedirs('figures/GCCA/MrBean')\n",
    "utils.plot_spatial_resp(F_train, corr_test, 'figures/GCCA/MrBean/'+str(n_sub)+'_cb.pdf', ifISC=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCCA = algo.GeneralizedCCA([EEG_clean], fs, L=5, offset=2, n_components=10, signifi_level=True)\n",
    "corr_train, corr_test, cov_train, cov_test, tsc_train, tsc_test, dist_train, dist_test, W_train, F_train = GCCA.cross_val()\n",
    "if not os.path.exists('figures/GCCA/MrBean'):\n",
    "    os.makedirs('figures/GCCA/MrBean')\n",
    "utils.plot_spatial_resp(F_train, corr_test, 'figures/GCCA/MrBean/clean_'+str(n_sub)+'_cb.pdf', ifISC=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4780ce94013b4ad826834d504b051d615119766f3ac7f8bac99efc1ee879921"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
